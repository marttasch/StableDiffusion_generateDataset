{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "from torch._C import TensorType\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from uuid import uuid4 as uu\n",
    "import shutil\n",
    "import os\n",
    "from tensorboard import program\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plot tensorboard metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "\n",
    "class TensorBoard:\n",
    "    def __init__(self, tensor_board_root: str):\n",
    "        self.tensor_board_root = tensor_board_root\n",
    "        print('init writer')\n",
    "        self.writer = SummaryWriter(tensor_board_root)\n",
    "\n",
    "    def init_tensorboard(self):\n",
    "        self.gen_session_id()\n",
    "        self.launch_tensorboard()\n",
    "        self.create_launchTensorboard_script()\n",
    "\n",
    "    def launch_tensorboard(self):\n",
    "        print('launch tensorboard')\n",
    "      \n",
    "        tensorboard_command = [\"tensorboard\", \"--logdir\", self.tensor_board_root]\n",
    "        cmd = f\"start cmd /k {' '.join(tensorboard_command)}\"\n",
    "        print(f\"\\nExecuting command: {cmd}\")\n",
    "        os.system(cmd)\n",
    "\n",
    "    def create_launchTensorboard_script(self):\n",
    "        # Create a script to launch tensorboard, place it in the tensorboard root\n",
    "        script = f\"tensorboard --logdir {self.tensor_board_root}\"\n",
    "        with open(os.path.join(self.tensor_board_root, 'launch_tensorboard.bat'), 'w') as f:\n",
    "            f.write(script)\n",
    "\n",
    "    def gen_session_id(self) -> str:\n",
    "        day = str(datetime.date.today().day).rjust(2, '0')\n",
    "        month = str(datetime.date.today().month).rjust(2, '0')\n",
    "        year = str(datetime.date.today().year)[-2:]\n",
    "        hour = str(datetime.datetime.now().hour).rjust(2, '0')\n",
    "        minute = str(datetime.datetime.now().minute).rjust(2, '0')\n",
    "        self.session_id = f'{day}-{month}-{year}_{hour}-{minute}_{str(uu())[-8:]}'\n",
    "        print(f\"Session ID: {self.session_id}\")\n",
    "        return self.session_id\n",
    "\n",
    "\n",
    "    def write_board(self, epoch: int, train_loss: int, train_accuracy, train_recall, train_precision, test_loss, test_accuracy, test_recall, test_precision, current_learning_rate: float):\n",
    "      \n",
    "        # Calc metric and add scalars\n",
    "        self.writer.add_scalars(f'Loss/{self.session_id}', {'Train': train_loss, 'Test': test_loss}, epoch)\n",
    "\n",
    "        self.writer.add_scalars(f'Accuracy/{self.session_id}', {'Train': train_accuracy, 'Test': test_accuracy}, epoch)\n",
    "\n",
    "        self.writer.add_scalars(f'Recall/{self.session_id}', {'Train': train_recall, 'Test': test_recall}, epoch)\n",
    "\n",
    "        self.writer.add_scalars(f'Precision/{self.session_id}', {'Train': train_precision, 'Test': test_precision}, epoch)\n",
    "\n",
    "        self.writer.add_scalar(f'Learning Rate/{self.session_id}', current_learning_rate, epoch)\n",
    "\n",
    "        self.writer.flush()\n",
    "\n",
    "    def write_confusion_matrix(self, epoch: int, confusion_matrix):\n",
    "        # log confusion matrix\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        self.writer.add_figure('Confusion Matrix', plt.gcf(), global_step=epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def write_parameter_histogram(self, model, epoch):\n",
    "        # log parameter distributions\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            plt.hist(param.flatten().detach().cpu().numpy(), bins=50, alpha=0.5, label=name)\n",
    "            plt.legend()\n",
    "            plt.title('Parameter Histograms')\n",
    "            self.writer.add_figure('Parameter Histograms', plt.gcf(), global_step=epoch)\n",
    "            self.writer.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===== Plot TensorBoard Metrics =====\n",
    "\n",
    "\n",
    "    def extract_tensorboard_data(self, log_dir=None):\n",
    "        \"\"\"\n",
    "        Extracts data from TensorBoard log files.\n",
    "\n",
    "        Args:\n",
    "        - log_dir (str): Path to the directory containing TensorBoard event files.\n",
    "\n",
    "        Returns:\n",
    "        - data (dict): Dictionary containing metric data {metric_name: [(step1, value1), (step2, value2), ...]}.\n",
    "        \"\"\"\n",
    "        if log_dir is None:\n",
    "            log_dir = self.tensor_board_root\n",
    "        data = {}\n",
    "        events = {}\n",
    "\n",
    "        for root, _, files in os.walk(log_dir):\n",
    "            for file in files:\n",
    "                if file.startswith(\"events.out\"):\n",
    "                    event_path = os.path.join(root, file)\n",
    "                    for event in summary_iterator(event_path):\n",
    "                        events[event.step] = event\n",
    "                        for value in event.summary.value:\n",
    "                            if value.tag not in data:\n",
    "                                data[value.tag] = []\n",
    "                            data[value.tag].append((event.step, value.simple_value))\n",
    "        return data, events\n",
    "\n",
    "    def plot_metrics(self, metric_values, label, title, save_path):\n",
    "        \"\"\"\n",
    "        Plots and saves metrics as images.\n",
    "\n",
    "        Args:\n",
    "        - metrics (dict): Dictionary of metrics to plot.\n",
    "        - save_path (str): Path to save the plot as an image.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        steps, values = zip(*metric_values)\n",
    "        plt.plot(steps, values, label=label, marker='o', markersize=3)\n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Value')\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "        #plt.savefig(f\"{save_path}.png\")\n",
    "        plt.show()\n",
    "        #plt.close()\n",
    "\n",
    "\n",
    "    def plot_tensorboard_metrics(self, log_dir=None, title='TensorBoard Metrics', xlabel='Step', ylabel='Value', save_path='tensorboard_plot'):\n",
    "        \"\"\"\n",
    "        Extracts and plots TensorBoard metrics as images.\n",
    "\n",
    "        Args:\n",
    "        - log_dir (str): Path to the directory containing TensorBoard event files.\n",
    "        - title (str): Title of the plot.\n",
    "        - xlabel (str): Label for the x-axis.\n",
    "        - ylabel (str): Label for the y-axis.\n",
    "        - save_path (str): Path to save the plot as an image.\n",
    "        \"\"\"\n",
    "        if log_dir is None:\n",
    "            log_dir = self.tensor_board_root\n",
    "        metric_data = self.extract_tensorboard_data(log_dir)\n",
    "\n",
    "        # Split into train and test metrics\n",
    "        accuracy_values = [(step, value) for sublist in {metric: metric_data[metric] for metric in metric_data.keys() if 'Accuracy' in metric}.values() for step, value in sublist]\n",
    "        loss_values = [(step, value) for sublist in {metric: metric_data[metric] for metric in metric_data.keys() if 'Loss' in metric}.values() for step, value in sublist]\n",
    "        recall_values = [(step, value) for sublist in {metric: metric_data[metric] for metric in metric_data.keys() if 'Recall' in metric}.values() for step, value in sublist]\n",
    "        precision_values = [(step, value) for sublist in {metric: metric_data[metric] for metric in metric_data.keys() if 'Precision' in metric}.values() for step, value in sublist]\n",
    "        learning_rate_values = [(step, value) for sublist in {metric: metric_data[metric] for metric in metric_data.keys() if 'Learning Rate' in metric}.values() for step, value in sublist]\n",
    "        \n",
    "        self.plot_metrics(accuracy_values, 'Accuracy', title, save_path)\n",
    "        # Call the function for each metric\n",
    "        # self.plot_metrics(accuracies, 'accuracies_plot')\n",
    "        # self.plot_metrics(losses, 'losses_plot')\n",
    "        # self.plot_metrics(recalls, 'recalls_plot')\n",
    "        # self.plot_metrics(precisions, 'precisions_plot')\n",
    "        # self.plot_metrics(learning_rates, 'learning_rates_plot')\n",
    "        \n",
    "        return metric_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_values = [(step, value) for sublist in {metric: metric_data[metric] for metric in metric_data.keys() if 'Accuracy' in metric}.values() for step, value in sublist]\n",
    "print(f'Acc Values: {accuracy_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"D:\\\\code\\\\Bachelorarbeit\\\\xx_code_BA\\\\trainingOutput\\\\2024-05-04_19-56-23_urinal_v2_resnet50\\\\tensorboard\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init writer\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type Event is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(metric_data, f)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# metric_data = tbh.plot_tensorboard_metrics()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# # dumb metric data as json as file\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# import json\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# with open('metric_data.json', 'w') as f:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#     json.dump(metric_data, f)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\miniconda3\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\miniconda3\\Lib\\json\\encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Martin\\miniconda3\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\miniconda3\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Martin\\miniconda3\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Event is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import src.trainCNN.tensorboardHandler as tbh\n",
    "import json\n",
    "\n",
    "\n",
    "log_dir = \"D:\\\\code\\\\Bachelorarbeit\\\\xx_code_BA\\\\trainingOutput\\\\2024-05-04_19-56-23_urinal_v2_resnet50\\\\tensorboard\"\n",
    "\n",
    "\n",
    "tbh = TensorBoard(log_dir)\n",
    "\n",
    "\n",
    "metric_data, events = tbh.extract_tensorboard_data(log_dir)\n",
    "\n",
    "with open('metric_data.json', 'w') as f:\n",
    "    json.dump(metric_data, f)\n",
    "with open('events.json', 'w') as f:\n",
    "    json.dump(events, f)\n",
    "\n",
    "# metric_data = tbh.plot_tensorboard_metrics()\n",
    "\n",
    "# # dumb metric data as json as file\n",
    "# import json\n",
    "# with open('metric_data.json', 'w') as f:\n",
    "#     json.dump(metric_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual_metric_images_exact(logdir, output_dir):\n",
    "    \"\"\"\n",
    "    Reads TensorBoard log files and saves separate plot images for each metric,\n",
    "    combining both training and test data in one plot. Prints debug information.\n",
    "\n",
    "    Parameters:\n",
    "    - logdir: The directory where TensorBoard log files are located.\n",
    "    - output_dir: The directory where plot images should be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Dictionary to accumulate metrics by their exact names\n",
    "    metrics = {\n",
    "        \"Accuracy/Train\": [],\n",
    "        \"Accuracy/Test\": [],\n",
    "        \"Loss/Train\": [],\n",
    "        \"Loss/Test\": [],\n",
    "        \"Precision/Train\": [],\n",
    "        \"Precision/Test\": [],\n",
    "        \"Recall/Train\": [],\n",
    "        \"Recall/Test\": [],\n",
    "    }\n",
    "\n",
    "    # Traverse through event files and populate accumulators\n",
    "    for root, _, files in os.walk(logdir):\n",
    "        for file in files:\n",
    "            if \"events\" in file:\n",
    "                event_path = os.path.join(root, file)\n",
    "                event_acc = EventAccumulator(event_path)\n",
    "                event_acc.Reload()\n",
    "\n",
    "                # List available scalar tags\n",
    "                available_scalars = event_acc.Tags()[\"scalars\"]\n",
    "                print(f\"Available scalars in {event_path}: {available_scalars}\")\n",
    "\n",
    "                # Collect the relevant metrics\n",
    "                for tag in metrics:\n",
    "                    if tag in available_scalars:\n",
    "                        metrics[tag].extend(\n",
    "                            [(s.step, s.value) for s in event_acc.Scalars(tag)]\n",
    "                        )\n",
    "\n",
    "    # Function to plot each metric, combining training and test, and handle empty lists gracefully\n",
    "    def plot_metric(metric_name, train_tag, test_tag, title, ylabel):\n",
    "        train_data = metrics[train_tag]\n",
    "        test_data = metrics[test_tag]\n",
    "\n",
    "        # Debugging output if lists are empty\n",
    "        if not train_data:\n",
    "            print(f\"No training data found for {train_tag}\")\n",
    "        if not test_data:\n",
    "            print(f\"No test data found for {test_tag}\")\n",
    "\n",
    "        plt.figure()\n",
    "        if train_data:\n",
    "            plt.plot(*zip(*sorted(train_data)), label=\"Training\", color='blue')\n",
    "        if test_data:\n",
    "            plt.plot(*zip(*sorted(test_data)), label=\"Test\", color='orange')\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Steps\")\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "        # Save the plot as an image\n",
    "        filename = os.path.join(output_dir, f\"{metric_name}.png\")\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "    # Plot each of the following metrics as separate images\n",
    "    plot_metric(\"accuracy\", \"Accuracy/Train\", \"Accuracy/Test\", \"Accuracy\", \"Accuracy\")\n",
    "    plot_metric(\"loss\", \"Loss/Train\", \"Loss/Test\", \"Loss\", \"Loss\")\n",
    "    plot_metric(\"precision\", \"Precision/Train\", \"Precision/Test\", \"Precision\", \"Precision\")\n",
    "    plot_metric(\"recall\", \"Recall/Train\", \"Recall/Test\", \"Recall\", \"Recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714845391.mts_workstation.40156.0: ['Learning Rate/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714851415.mts_workstation.21924.0: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714852888.mts_workstation.21924.1: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853052.mts_workstation.21924.2: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853061.mts_workstation.21924.3: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853075.mts_workstation.21924.4: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853111.mts_workstation.21924.5: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853198.mts_workstation.21924.6: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853257.mts_workstation.21924.7: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853333.mts_workstation.21924.8: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714853944.mts_workstation.21924.9: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714854139.mts_workstation.21924.10: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714854153.mts_workstation.21924.11: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714854157.mts_workstation.21924.12: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714854165.mts_workstation.21924.13: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714854166.mts_workstation.21924.14: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714854185.mts_workstation.49108.0: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714860979.mts_workstation.49108.1: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714860987.mts_workstation.49108.2: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714861040.mts_workstation.5160.0: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714861173.mts_workstation.5160.1: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714861187.mts_workstation.3624.0: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714861265.mts_workstation.23300.0: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897448.mts_workstation.23300.1: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897455.mts_workstation.23300.2: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897489.mts_workstation.51880.0: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897632.mts_workstation.51880.1: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897735.mts_workstation.51880.2: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897755.mts_workstation.51880.3: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897761.mts_workstation.51880.4: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897887.mts_workstation.51880.5: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714897943.mts_workstation.51880.6: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898032.mts_workstation.51880.7: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898088.mts_workstation.51880.8: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898231.mts_workstation.51880.9: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898415.mts_workstation.51880.10: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898447.mts_workstation.51880.11: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898538.mts_workstation.51880.12: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898564.mts_workstation.51880.13: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898675.mts_workstation.51880.14: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898719.mts_workstation.51880.15: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898740.mts_workstation.51880.16: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714898800.mts_workstation.51880.17: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899003.mts_workstation.51880.18: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899040.mts_workstation.51880.19: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899067.mts_workstation.51880.20: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899427.mts_workstation.51880.21: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899473.mts_workstation.51880.22: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899558.mts_workstation.51880.23: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899570.mts_workstation.51880.24: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899594.mts_workstation.51880.25: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\events.out.tfevents.1714899638.mts_workstation.51880.26: []\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Accuracy_04-05-24_19-56_34c89e41_Test\\events.out.tfevents.1714845439.mts_workstation.40156.4: ['Accuracy/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Accuracy_04-05-24_19-56_34c89e41_Train\\events.out.tfevents.1714845439.mts_workstation.40156.3: ['Accuracy/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Loss_04-05-24_19-56_34c89e41_Test\\events.out.tfevents.1714845439.mts_workstation.40156.2: ['Loss/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Loss_04-05-24_19-56_34c89e41_Train\\events.out.tfevents.1714845439.mts_workstation.40156.1: ['Loss/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Precision_04-05-24_19-56_34c89e41_Test\\events.out.tfevents.1714845439.mts_workstation.40156.8: ['Precision/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Precision_04-05-24_19-56_34c89e41_Train\\events.out.tfevents.1714845439.mts_workstation.40156.7: ['Precision/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Recall_04-05-24_19-56_34c89e41_Test\\events.out.tfevents.1714845439.mts_workstation.40156.6: ['Recall/04-05-24_19-56_34c89e41']\n",
      "Available scalars in D:\\code\\Bachelorarbeit\\xx_code_BA\\trainingOutput\\2024-05-04_19-56-23_urinal_v2_resnet50\\tensorboard\\Recall_04-05-24_19-56_34c89e41_Train\\events.out.tfevents.1714845439.mts_workstation.40156.5: ['Recall/04-05-24_19-56_34c89e41']\n",
      "No training data found for Accuracy/Train\n",
      "No test data found for Accuracy/Test\n",
      "No training data found for Loss/Train\n",
      "No test data found for Loss/Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data found for Precision/Train\n",
      "No test data found for Precision/Test\n",
      "No training data found for Recall/Train\n",
      "No test data found for Recall/Test\n"
     ]
    }
   ],
   "source": [
    "plot_individual_metric_images_exact(log_dir, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:05.00\n"
     ]
    }
   ],
   "source": [
    "import src.mts_utils as mts\n",
    "import time\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "print(mts.get_TimeElapsed(starttime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
